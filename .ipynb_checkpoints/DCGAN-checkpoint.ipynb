{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-611db659be48>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/charles/Software/tensorflow/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/charles/Software/tensorflow/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/charles/Software/tensorflow/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/charles/Software/tensorflow/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/charles/Software/tensorflow/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# import mnist dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "lr_generator = 2e-3\n",
    "lr_discriminator = 2e-3\n",
    "\n",
    "# network parameters\n",
    "image_dim = 784 # mnist image 28*28*1\n",
    "noise_dim = 100 # noise data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-4-325270aa20fa>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-325270aa20fa>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    def generator(x, reuse=False):\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# build networks\n",
    "# network inputs\n",
    "noise_input = tf.placeholder(tf.float32, shape=[None, noise_dim])\n",
    "real_image_input = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "\n",
    "# a boolean to indicate batch normalization if it is training or inference time\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# LeakeyReLU\n",
    "def leakeyrelu(x, alpha=0.2):\n",
    "    return 0.5 * (1 + alpha) * x + 0.5 * (1 - alpha) * abs(x)\n",
    "\n",
    "# Genetator network\n",
    "# Input: Noise, Output: Image\n",
    "# Note that batch normalization has different behavior at training and inference time\n",
    "# we then use placeholder to indicate the layer if we are training or not.\n",
    "def generator(x, reuse=False):\n",
    "    With tf.variable_scope('Generator', reuse=reuse):\n",
    "        print(\"Generator:\")\n",
    "        # tensorflow layer automatically create variables and \n",
    "        # calculate their shape, based on the input.\n",
    "        x = tf.layers.dense(x, units=7*7*128)\n",
    "        print(\"1st dense layer:\", x)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        print(\"1st BN layer:\", x)\n",
    "        x = tf.nn.relu(x)\n",
    "        print(\"1st relu layer:\", x)\n",
    "        \n",
    "        # reshape to a 4D array of images: [batch, height, width, channels]\n",
    "        # new shape: (batch, 7, 7, 128)\n",
    "        x = tf.reshape(x, shape=[-1, 7, 7, 128])\n",
    "        print(\"reshape layer:\", x)\n",
    "        \n",
    "        # deconvolution, image shape: (batch, 14, 14, 64)\n",
    "        x = tf.layers.conv2d_transpose(x, 64, 5, strides=2, padding='same')\n",
    "        print(\"2nd deconv layer:\", x)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        print(\"2nd BN layer:\", x)\n",
    "        x = tf.nn.relu(x)\n",
    "        print(\"2nd relu layer:\", x)\n",
    "        \n",
    "        # deconvolution, image shape: (batch, 28, 28, 1)\n",
    "        x = tf.layers.conv2d_transpose(x, 1, 5, strides=2, padding='same')\n",
    "        print(\"3rd deconv layer:\", x)\n",
    "        # apply tanh for best scability - clip values to [-1, 1]\n",
    "        x = tf.nn.tanh(x)\n",
    "        print(\"3rd tanh layer:\", x)\n",
    "    return x\n",
    "\n",
    "# discriminator network\n",
    "# Input: image, output: prediction real/fake image\n",
    "def discriminator(x, reuse=False):\n",
    "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
    "        print(\"Discriminator\")\n",
    "        x = tf.layers.conv2d(x, 64, 5, strides=2, padding='same')\n",
    "        print(\"1st conv layer:\", x)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        print(\"1st BN layer:\", x)\n",
    "        x = leakeyrelu(x)\n",
    "        print(\"1st leakeyrelu layer:\", x)\n",
    "        \n",
    "        x = tf.layers.conv2d(x, 128, 5, strides=2, padding='same')\n",
    "        print(\"2nd conv layer:\", x)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        print(\"2nd BN layer:\", x)\n",
    "        x = leakeyrelu(x)\n",
    "        print(\"2nd leakeyrelu layer:\", x)\n",
    "        \n",
    "        # flatten\n",
    "        x = tf.reshape(x, shape=[-1, 7 * 7 * 128])\n",
    "        print(\"reshpe layer:\",x)\n",
    "        \n",
    "        x = tf.layers.dense(x, 1024)\n",
    "        print(\"3rd dense layer:\", x)\n",
    "        x = tf.layers.batch_normalization(x, training=is_training)\n",
    "        print(\"3rd BN layer:\", x)\n",
    "        x = leakeyrelu(x)\n",
    "        print(\"3rd leakeyrelu layer:\", x)\n",
    "        \n",
    "        # output 2 classes: real and fake image\n",
    "        x = tf.layers.dense(x, 2)\n",
    "        print(\"last dense layer:\", x)\n",
    "    return x\n",
    "# build generator network\n",
    "gen_sample = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
